{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b930d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Union, List, Tuple\n",
    "import scipy\n",
    "from numpy.random import standard_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e3c489e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.2, 0.8]\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=100000, \n",
    "    n_features=20, \n",
    "    n_informative=2,      \n",
    "    weights=weights, \n",
    "    random_state=42,\n",
    "    n_redundant=2)\n",
    "\n",
    "num_samples = X.shape[0]\n",
    "\n",
    "categorical_col1 = np.random.choice(['A', 'B', 'C'], size=num_samples)\n",
    "categorical_col2 = np.random.choice(['X', 'Y', 'Z'], size=num_samples)\n",
    "\n",
    "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a71ca223",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(df_train[\"feature_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "33a79f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Convenção de hurst é que separar as amostras em pequenas amostras na qual o tamanho é proporcional à potência de dois'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Convenção de hurst é que separar as amostras em pequenas amostras na qual o tamanho é proporcional à potência de dois\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9bfdb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hurst_v1(X):\n",
    "    X = np.asarray(X)\n",
    "    #rolling = np.diff(X)\n",
    "    rolling = X\n",
    "    size = len(X)\n",
    "    exp = np.floor(math.log2(size)).astype(int)\n",
    "    subsample_sizes = []\n",
    "    for pow in range(1, exp + 1):\n",
    "        subsample = 2 ** pow\n",
    "        if size % subsample == 0:\n",
    "            subsample_sizes.append(subsample)\n",
    "    for subsample in subsample_sizes:\n",
    "        window_indices = [np.arange(i, i + subsample) for i in range(0, size, subsample)]\n",
    "        mean = np.mean(rolling[window_indices], axis=1)\n",
    "        S = np.std(rolling[window_indices], axis=1, ddof=1)\n",
    "        demeaned = rolling[window_indices] - mean[:, None]\n",
    "        cumsum = np.cumsum(demeaned, axis=1)\n",
    "        R = np.max(cumsum, axis=1) - np.min(cumsum, axis=1)\n",
    "        r_s = R / S\n",
    "    return r_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "1cacb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hurst_v2(X: Union[np.ndarray, List[float]]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the Hurst exponent using a rescaled range (R/S) analysis approach.\n",
    "\n",
    "    The Hurst exponent is a measure of long-term memory of time series. It relates \n",
    "    to the autocorrelations of the time series and the rate at which these decrease \n",
    "    as the lag between pairs of values increases. This implementation uses a \n",
    "    vectorized approach for improved performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray of shape (n_samples,) or list of float\n",
    "        Input 1D time series data for which to calculate the Hurst exponent.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The estimated Hurst exponent value. Interpretation:\n",
    "        - 0 < H < 0.5: Mean-reverting (anti-persistent) series\n",
    "        - H = 0.5: Geometric Brownian motion (uncorrelated steps)\n",
    "        - 0.5 < H < 1: Trending (persistent) series with long-term memory\n",
    "        - H = 1: Perfectly trending series\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input data has less than 10 samples (insufficient for reliable estimation).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The method works by:\n",
    "    1. Calculating differences of the input series\n",
    "    2. Dividing the series into windows of varying sizes (powers of 2)\n",
    "    3. Calculating the rescaled range (R/S) for each window size\n",
    "    4. Performing linear regression on log(R/S) vs log(window size)\n",
    "    5. The slope of this regression gives the Hurst exponent estimate\n",
    "\n",
    "    The implementation uses vectorized operations for better performance compared\n",
    "    to iterative versions. For reliable results, the time series should have at\n",
    "    least 100-1000 data points.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    rolling = np.diff(X)\n",
    "    size = len(rolling)\n",
    "    \n",
    "    if size < 10:\n",
    "        raise ValueError(\"Dados insuficientes para calcular o expoente de Hurst.\")\n",
    "    \n",
    "    max_pow = int(np.floor(math.log2(size)))\n",
    "    subsamples = [2 ** pow for pow in range(1, max_pow + 1)]\n",
    "\n",
    "    r_s = np.zeros(len(subsamples), dtype=float)\n",
    "    \n",
    "    for i in range(len(subsamples)):\n",
    "        length_windows = size // subsamples[i]\n",
    "        \n",
    "        windows = rolling[:length_windows * subsamples[i]].reshape(length_windows, subsamples[i])\n",
    "        \n",
    "        mean = np.mean(windows, axis=1, keepdims=True)\n",
    "        S = np.std(windows, axis=1, ddof=1)\n",
    "        demeaned = windows - mean\n",
    "        cumsum = np.cumsum(demeaned, axis=1)\n",
    "        R = np.max(cumsum, axis=1) - np.min(cumsum, axis=1)\n",
    "        r_s[i] = np.mean(R / S)\n",
    "    \n",
    "    log_sizes = np.log(subsamples)\n",
    "    log_r_s = np.log(r_s)\n",
    "    slope, _, _, _, _ = scipy.stats.linregress(log_sizes, log_r_s)\n",
    "    \n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f0b14a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.1586313770243084)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hurst_v2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "de27985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hurst_v3(X: Union[np.ndarray, List[float]]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calculate the Hurst exponent using a rescaled range (R/S) analysis approach with p-value for random walk hypothesis.\n",
    "\n",
    "    The Hurst exponent is a measure of long-term memory of time series. It relates \n",
    "    to the autocorrelations of the time series and the rate at which these decrease \n",
    "    as the lag between pairs of values increases.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : Union[np.ndarray, List[float]]\n",
    "        Input 1D time series data for which to calculate the Hurst exponent.\n",
    "        Must contain at least 10 samples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]\n",
    "        (Hurst exponent, p-value for H=0.5 hypothesis)\n",
    "        The estimated Hurst exponent value. Interpretation:\n",
    "        - 0 < H < 0.5: Mean-reverting (anti-persistent) series\n",
    "        - H = 0.5: Geometric Brownian motion (random walk)\n",
    "        - 0.5 < H < 1: Trending (persistent) series with long-term memory\n",
    "        - H = 1: Perfectly trending series\n",
    "        p-value interpretation:\n",
    "        - p < threshold: Reject random walk hypothesis (significant persistence/mean-reversion)\n",
    "        - p >= threshold: Cannot reject random walk hypothesis\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input data has less than 10 samples (insufficient for reliable estimation).\n",
    "    TypeError\n",
    "        If input is not a list or numpy array.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    rolling = np.diff(X)\n",
    "    size = len(rolling)\n",
    "    \n",
    "    if size < 10:\n",
    "        raise ValueError(\"Insufficient data points (minimum 10 required)\")\n",
    "\n",
    "    max_power = int(np.floor(math.log2(size)))\n",
    "    window_sizes = [2 ** power for power in range(1, max_power + 1)]\n",
    "\n",
    "    rescaled_ranges = _calculate_rescaled_ranges(rolling, window_sizes)\n",
    "    \n",
    "    log_sizes = np.log(window_sizes)\n",
    "    log_r_s = np.log(rescaled_ranges)\n",
    "    slope, _, _, _, se = scipy.stats.linregress(log_sizes, log_r_s)\n",
    "    \n",
    "    p_value = _hypothesis_test_random_walk(slope, se, len(window_sizes))\n",
    "\n",
    "    return float(slope), float(p_value)\n",
    "\n",
    "\n",
    "def _calculate_rescaled_ranges(\n",
    "    rolling: np.ndarray,\n",
    "    window_sizes: List[int]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Helper function to calculate rescaled ranges (R/S) for each window size.\"\"\"\n",
    "    r_s = np.zeros(len(window_sizes), dtype=np.float64)\n",
    "\n",
    "    for i, window_size in enumerate(window_sizes):\n",
    "        n_windows = len(rolling) // window_size\n",
    "        truncated_size = n_windows * window_size\n",
    "        \n",
    "        windows = rolling[:truncated_size].reshape(n_windows, window_size)\n",
    "        \n",
    "        means = np.mean(windows, axis=1, keepdims=True)\n",
    "        std_devs = np.std(windows, axis=1, ddof=1)\n",
    "        demeaned = windows - means\n",
    "        cumulative_sums = np.cumsum(demeaned, axis=1)\n",
    "        ranges = np.max(cumulative_sums, axis=1) - np.min(cumulative_sums, axis=1)\n",
    "        \n",
    "        r_s[i] = np.mean(ranges / std_devs)\n",
    "\n",
    "    return r_s\n",
    "\n",
    "\n",
    "def _hypothesis_test_random_walk(hurst: float, se: float, n: int) -> float:\n",
    "    \"\"\"Helper function to test if Hurst exponent is significantly different from random_walk (0.5)\"\"\"\n",
    "    random_walk = 0.5\n",
    "    t_stat = (hurst - random_walk) / se \n",
    "    ddof = n - 2\n",
    "    return 2 * scipy.stats.t.sf(abs(t_stat), ddof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "49a550b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1586313770243084, 6.899049706887254e-10)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hurst_v3(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6e6d5",
   "metadata": {},
   "source": [
    "# Na hora do teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "3fc3f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração\n",
    "np.random.seed(42)\n",
    "n_points = 1000\n",
    "trend = np.linspace(0, 10, n_points)\n",
    "noise_trend = np.cumsum(standard_normal(n_points) * 0.1)\n",
    "mean_reversion = np.zeros(n_points)\n",
    "for t in range(1, n_points):\n",
    "    mean_reversion[t] = mean_reversion[t-1] * 0.6 + standard_normal() * 0.5\n",
    "brownian = np.cumsum(standard_normal(n_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "54287074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6419241912818302, 0.000952023886777138)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hurst_v3(noise_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "afdb1ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3685698852341455, 0.05402692976986088)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hurst_v3(mean_reversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "88b2cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5970314294136879, 0.04084100480394357)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hurst_v3(brownian)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyshift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
